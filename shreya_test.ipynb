{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e16f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 0.76373\n",
      "Trial 1: Accuracy = 0.89410\n",
      "Trial 2: Accuracy = 0.88592\n",
      "Trial 3: Accuracy = 0.88991\n",
      "Trial 4: Accuracy = 0.63928\n",
      "Trial 5: Accuracy = 0.85096\n",
      "Trial 6: Accuracy = 0.89397\n",
      "Trial 7: Accuracy = 0.88045\n",
      "Trial 8: Accuracy = 0.82206\n",
      "Trial 9: Accuracy = 0.26833\n",
      "Trial 10: Accuracy = 0.90195\n",
      "Trial 11: Accuracy = 0.90272\n",
      "Trial 12: Accuracy = 0.90523\n",
      "Trial 13: Accuracy = 0.90530\n",
      "Trial 14: Accuracy = 0.89532\n",
      "Trial 15: Accuracy = 0.90601\n",
      "Trial 16: Accuracy = 0.90684\n",
      "Trial 17: Accuracy = 0.90536\n",
      "Trial 18: Accuracy = 0.90472\n",
      "Trial 19: Accuracy = 0.89558\n",
      "\n",
      "Best CV Accuracy: 0.9068437160050907\n",
      "Best Hyperparameters:\n",
      "max_depth: 12\n",
      "min_child_weight: 5\n",
      "learning_rate: 0.028530248692968278\n",
      "subsample: 0.790747100681893\n",
      "colsample_bytree: 0.5668480674558728\n",
      "reg_alpha: 1.3824572149260739\n",
      "reg_lambda: 3.0432020762518794\n",
      "gamma: 0.7593682249421783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [23:52:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "# ---------------------\n",
    "# Settings\n",
    "# ---------------------\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "TARGET = \"WeightCategory\"\n",
    "targetMap = {\n",
    "    'Insufficient_Weight':0,'Normal_Weight':1,\n",
    "    'Overweight_Level_I':2,'Overweight_Level_II':3, \n",
    "    'Obesity_Type_I':4,'Obesity_Type_II':5 ,'Obesity_Type_III':6\n",
    "}\n",
    "targetMap_reversed = {v:k for k,v in targetMap.items()}\n",
    "\n",
    "# ---------------------\n",
    "# Cross-validation function\n",
    "# ---------------------\n",
    "def cross_val_score_pipeline(X_tr, y_tr, pipeline, skf, verbose=False):\n",
    "    \"\"\"\n",
    "    Custom cross-validation for a pipeline. Returns mean accuracy.\n",
    "    \"\"\"\n",
    "    X = X_tr.copy()\n",
    "    y = y_tr.copy()\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        model = clone(pipeline)\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"FOLD {fold}: Accuracy = {acc:.5f}\")\n",
    "\n",
    "    mean_acc = np.mean(val_scores)\n",
    "    if verbose:\n",
    "        print(f\"Mean CV Accuracy: {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Pipeline preparation\n",
    "# ---------------------\n",
    "def xgb_pipeline(df_train, df_test, xgb_model):\n",
    "    \"\"\"\n",
    "    Prepares train/test features and returns pipeline.\n",
    "    Drops 'id' column automatically.\n",
    "    \"\"\"\n",
    "    X_train = df_train.copy()\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    # Drop ID if exists\n",
    "    if 'id' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['id'])\n",
    "    if 'id' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['id'])\n",
    "    \n",
    "    y_train = X_train.pop(TARGET).map(targetMap)\n",
    "\n",
    "    categorical_columns = list(X_train.select_dtypes(include='object').columns)\n",
    "    numerical_columns = list(X_train.select_dtypes(exclude='object').columns)\n",
    "\n",
    "    cat_transformer = make_pipeline(MEstimateEncoder())\n",
    "    num_transformer = make_pipeline(StandardScaler())\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_transformer, numerical_columns),\n",
    "        (\"cat\", cat_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, xgb_model)\n",
    "\n",
    "    return X_train, y_train, X_test, pipeline\n",
    "\n",
    "# ---------------------\n",
    "# Optuna objective\n",
    "# ---------------------\n",
    "def objective(trial, pipeline, X_train, y_train, skf):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "    pipeline.named_steps['xgbclassifier'].set_params(**params)\n",
    "\n",
    "    mean_acc = cross_val_score_pipeline(X_train, y_train, pipeline, skf)\n",
    "    print(f\"Trial {trial.number}: Accuracy = {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Load data\n",
    "# ---------------------\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = df_test['id'].copy() if 'id' in df_test.columns else pd.Series(range(len(df_test)))\n",
    "\n",
    "# ---------------------\n",
    "# Prepare pipeline & model\n",
    "# ---------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, pipeline = xgb_pipeline(df_train, df_test, xgb_model)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Optuna hyperparameter tuning\n",
    "# ---------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    partial(objective, pipeline=pipeline, X_train=X_train, y_train=y_train, skf=skf),\n",
    "    n_trials=20\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Best trial results\n",
    "# ---------------------\n",
    "trial = study.best_trial\n",
    "print(\"\\nBest CV Accuracy:\", trial.value)\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------------\n",
    "# Train final model with best hyperparameters\n",
    "# ---------------------\n",
    "best_params = trial.params\n",
    "xgb_model_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, final_pipeline = xgb_pipeline(df_train, df_test, xgb_model_final)\n",
    "\n",
    "# Fit on full training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_numeric = final_pipeline.predict(X_test)\n",
    "test_preds_labels = [targetMap_reversed[i] for i in test_preds_numeric]\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'WeightCategory': test_preds_labels\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"\\nSaved predictions to submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f0fbfa",
   "metadata": {},
   "source": [
    "**the above gave 91% accuracy on kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9378313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 0.88058\n",
      "Trial 1: Accuracy = 0.88341\n",
      "Trial 2: Accuracy = 0.87137\n",
      "Trial 3: Accuracy = 0.86860\n",
      "Trial 4: Accuracy = 0.78691\n",
      "Trial 5: Accuracy = 0.89049\n",
      "Trial 6: Accuracy = 0.87311\n",
      "Trial 7: Accuracy = 0.88959\n",
      "Trial 8: Accuracy = 0.90073\n",
      "Trial 9: Accuracy = 0.89802\n",
      "Trial 10: Accuracy = 0.86867\n",
      "Trial 11: Accuracy = 0.89738\n",
      "Trial 12: Accuracy = 0.88360\n",
      "Trial 13: Accuracy = 0.89384\n",
      "Trial 14: Accuracy = 0.89925\n",
      "Trial 15: Accuracy = 0.89519\n",
      "Trial 16: Accuracy = 0.89339\n",
      "Trial 17: Accuracy = 0.89551\n",
      "Trial 18: Accuracy = 0.85482\n",
      "Trial 19: Accuracy = 0.88772\n",
      "\n",
      "Best CV Accuracy: 0.9007277876784056\n",
      "Best Hyperparameters:\n",
      "max_depth: 10\n",
      "min_child_weight: 7\n",
      "learning_rate: 0.07521423681092154\n",
      "subsample: 0.9580620215961363\n",
      "colsample_bytree: 0.23429837650701\n",
      "reg_alpha: 6.908145127016929\n",
      "reg_lambda: 4.307601433813856\n",
      "gamma: 0.5854726407556704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shrey\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\training.py:199: UserWarning: [00:47:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.preprocessing import StandardScaler, RobustScalery6\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "# ---------------------\n",
    "# Settings\n",
    "# ---------------------\n",
    "warnings.filterwarnings(\"ignore\", message=\"X does not have valid feature names\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "TARGET = \"WeightCategory\"\n",
    "targetMap = {\n",
    "    'Insufficient_Weight':0,'Normal_Weight':1,\n",
    "    'Overweight_Level_I':2,'Overweight_Level_II':3, \n",
    "    'Obesity_Type_I':4,'Obesity_Type_II':5 ,'Obesity_Type_III':6\n",
    "}\n",
    "targetMap_reversed = {v:k for k,v in targetMap.items()}\n",
    "\n",
    "# ---------------------\n",
    "# Cross-validation function\n",
    "# ---------------------\n",
    "def cross_val_score_pipeline(X_tr, y_tr, pipeline, skf, verbose=False):\n",
    "    \"\"\"\n",
    "    Custom cross-validation for a pipeline. Returns mean accuracy.\n",
    "    \"\"\"\n",
    "    X = X_tr.copy()\n",
    "    y = y_tr.copy()\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        model = clone(pipeline)\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"FOLD {fold}: Accuracy = {acc:.5f}\")\n",
    "\n",
    "    mean_acc = np.mean(val_scores)\n",
    "    if verbose:\n",
    "        print(f\"Mean CV Accuracy: {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Pipeline preparation\n",
    "# ---------------------\n",
    "def xgb_pipeline(df_train, df_test, xgb_model):\n",
    "    \"\"\"\n",
    "    Prepares train/test features and returns pipeline.\n",
    "    Drops 'id' column automatically.\n",
    "    \"\"\"\n",
    "    X_train = df_train.copy()\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    # Drop ID if exists\n",
    "    if 'id' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['id'])\n",
    "    if 'id' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['id'])\n",
    "    \n",
    "    y_train = X_train.pop(TARGET).map(targetMap)\n",
    "\n",
    "    categorical_columns = list(X_train.select_dtypes(include='object').columns)\n",
    "    numerical_columns = list(X_train.select_dtypes(exclude='object').columns)\n",
    "\n",
    "    cat_transformer = make_pipeline(MEstimateEncoder())\n",
    "    num_transformer = make_pipeline(RobustScaler())\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", num_transformer, numerical_columns),\n",
    "        (\"cat\", cat_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, xgb_model)\n",
    "\n",
    "    return X_train, y_train, X_test, pipeline\n",
    "\n",
    "# ---------------------\n",
    "# Optuna objective\n",
    "# ---------------------\n",
    "def objective(trial, pipeline, X_train, y_train, skf):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "    pipeline.named_steps['xgbclassifier'].set_params(**params)\n",
    "\n",
    "    mean_acc = cross_val_score_pipeline(X_train, y_train, pipeline, skf)\n",
    "    print(f\"Trial {trial.number}: Accuracy = {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Load data\n",
    "# ---------------------\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = df_test['id'].copy() if 'id' in df_test.columns else pd.Series(range(len(df_test)))\n",
    "\n",
    "# ---------------------\n",
    "# Prepare pipeline & model\n",
    "# ---------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, pipeline = xgb_pipeline(df_train, df_test, xgb_model)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Optuna hyperparameter tuning\n",
    "# ---------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    partial(objective, pipeline=pipeline, X_train=X_train, y_train=y_train, skf=skf),\n",
    "    n_trials=20\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Best trial results\n",
    "# ---------------------\n",
    "trial = study.best_trial\n",
    "print(\"\\nBest CV Accuracy:\", trial.value)\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------------\n",
    "# Train final model with best hyperparameters\n",
    "# ---------------------\n",
    "best_params = trial.params\n",
    "xgb_model_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, final_pipeline = xgb_pipeline(df_train, df_test, xgb_model_final)\n",
    "\n",
    "# Fit on full training data\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "test_preds_numeric = final_pipeline.predict(X_test)\n",
    "test_preds_labels = [targetMap_reversed[i] for i in test_preds_numeric]\n",
    "\n",
    "# Save submission\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'WeightCategory': test_preds_labels\n",
    "})\n",
    "submission.to_csv(\"submission_robust_scaler.csv\", index=False)\n",
    "print(\"\\nSaved predictions to submission.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab405152",
   "metadata": {},
   "source": [
    "**The above gave 90.9% accuracy on kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "200e8c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 0.86313\n",
      "Trial 1: Accuracy = 0.86094\n",
      "Trial 2: Accuracy = 0.87961\n",
      "Trial 3: Accuracy = 0.86345\n",
      "Trial 4: Accuracy = 0.89757\n",
      "Trial 5: Accuracy = 0.41203\n",
      "Trial 6: Accuracy = 0.72871\n",
      "Trial 7: Accuracy = 0.88315\n",
      "Trial 8: Accuracy = 0.88328\n",
      "Trial 9: Accuracy = 0.88547\n",
      "Trial 10: Accuracy = 0.86738\n",
      "Trial 11: Accuracy = 0.88792\n",
      "Trial 12: Accuracy = 0.89609\n",
      "Trial 13: Accuracy = 0.90317\n",
      "Trial 14: Accuracy = 0.90485\n",
      "Trial 15: Accuracy = 0.90060\n",
      "Trial 16: Accuracy = 0.88747\n",
      "Trial 17: Accuracy = 0.88721\n",
      "Trial 18: Accuracy = 0.90021\n",
      "Trial 19: Accuracy = 0.90053\n",
      "Trial 20: Accuracy = 0.90652\n",
      "Trial 21: Accuracy = 0.90581\n",
      "Trial 22: Accuracy = 0.90633\n",
      "Trial 23: Accuracy = 0.90620\n",
      "Trial 24: Accuracy = 0.90356\n",
      "Trial 25: Accuracy = 0.89841\n",
      "Trial 26: Accuracy = 0.90176\n",
      "Trial 27: Accuracy = 0.90697\n",
      "Trial 28: Accuracy = 0.90511\n",
      "Trial 29: Accuracy = 0.89912\n",
      "\n",
      "Best CV Accuracy: 0.9069724161071184\n",
      "Best Hyperparameters:\n",
      "max_depth: 14\n",
      "min_child_weight: 9\n",
      "learning_rate: 0.05094902452143167\n",
      "subsample: 0.8011043351246342\n",
      "colsample_bytree: 0.4392231417422889\n",
      "reg_alpha: 0.18006451040285643\n",
      "reg_lambda: 0.742826114805604\n",
      "gamma: 1.2963449364992286\n",
      "\n",
      "Saved predictions to submission_boxcox_std_label.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "\n",
    "# ---------------------\n",
    "# Settings\n",
    "# ---------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "TARGET = \"WeightCategory\"\n",
    "targetMap = {\n",
    "    'Insufficient_Weight':0,'Normal_Weight':1,\n",
    "    'Overweight_Level_I':2,'Overweight_Level_II':3, \n",
    "    'Obesity_Type_I':4,'Obesity_Type_II':5 ,'Obesity_Type_III':6\n",
    "}\n",
    "targetMap_reversed = {v:k for k,v in targetMap.items()}\n",
    "\n",
    "# ---------------------\n",
    "# Cross-validation function\n",
    "# ---------------------\n",
    "def cross_val_score_pipeline(X_tr, y_tr, pipeline, skf, verbose=False):\n",
    "    X = X_tr.copy()\n",
    "    y = y_tr.copy()\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        model = clone(pipeline)\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"FOLD {fold}: Accuracy = {acc:.5f}\")\n",
    "\n",
    "    mean_acc = np.mean(val_scores)\n",
    "    if verbose:\n",
    "        print(f\"Mean CV Accuracy: {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Pipeline preparation\n",
    "# ---------------------\n",
    "def xgb_pipeline(df_train, df_test, xgb_model):\n",
    "    X_train = df_train.copy()\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    # Drop ID if exists\n",
    "    if 'id' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['id'])\n",
    "    if 'id' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['id'])\n",
    "    \n",
    "    y_train = X_train.pop(TARGET).map(targetMap)\n",
    "\n",
    "    # numeric and categorical columns\n",
    "    numeric_cols = list(X_train.select_dtypes(exclude='object').columns)\n",
    "    categorical_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "    numeric_cols_without_age = [c for c in numeric_cols if c != 'Age']\n",
    "\n",
    "    # Numeric transformer\n",
    "    num_transformer = ColumnTransformer([\n",
    "        ('boxcox', PowerTransformer(method='box-cox'), ['Age']),\n",
    "        ('scale', StandardScaler(), numeric_cols_without_age)\n",
    "    ])\n",
    "\n",
    "    # Categorical transformer\n",
    "    cat_transformer = OrdinalEncoder()\n",
    "\n",
    "    # Full preprocessor\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_transformer, numeric_cols),\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, xgb_model)\n",
    "    return X_train, y_train, X_test, pipeline\n",
    "\n",
    "# ---------------------\n",
    "# Optuna objective\n",
    "# ---------------------\n",
    "def objective(trial, pipeline, X_train, y_train, skf):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "    pipeline.named_steps['xgbclassifier'].set_params(**params)\n",
    "\n",
    "    mean_acc = cross_val_score_pipeline(X_train, y_train, pipeline, skf)\n",
    "    print(f\"Trial {trial.number}: Accuracy = {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Load data\n",
    "# ---------------------\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = df_test['id'].copy() if 'id' in df_test.columns else pd.Series(range(len(df_test)))\n",
    "\n",
    "# ---------------------\n",
    "# Prepare pipeline & model\n",
    "# ---------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, pipeline = xgb_pipeline(df_train, df_test, xgb_model)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Optuna hyperparameter tuning\n",
    "# ---------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    partial(objective, pipeline=pipeline, X_train=X_train, y_train=y_train, skf=skf),\n",
    "    n_trials=30\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Best trial results\n",
    "# ---------------------\n",
    "trial = study.best_trial\n",
    "print(\"\\nBest CV Accuracy:\", trial.value)\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------------\n",
    "# Train final model with best hyperparameters\n",
    "# ---------------------\n",
    "best_params = trial.params\n",
    "xgb_model_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, final_pipeline = xgb_pipeline(df_train, df_test, xgb_model_final)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------\n",
    "# Predict on test set\n",
    "# ---------------------\n",
    "test_preds_numeric = final_pipeline.predict(X_test)\n",
    "test_preds_labels = [targetMap_reversed[i] for i in test_preds_numeric]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'WeightCategory': test_preds_labels\n",
    "})\n",
    "submission.to_csv(\"submission_boxcox_std_label.csv\", index=False)\n",
    "print(\"\\nSaved predictions to submission_boxcox_std_label.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63ae5e6",
   "metadata": {},
   "source": [
    "**The above gave 91.267% accuracy on kaggle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1edc600a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 0.86789\n",
      "Trial 1: Accuracy = 0.89062\n",
      "Trial 2: Accuracy = 0.87684\n",
      "Trial 3: Accuracy = 0.86931\n",
      "Trial 4: Accuracy = 0.86139\n",
      "Trial 5: Accuracy = 0.89513\n",
      "Trial 6: Accuracy = 0.87665\n",
      "Trial 7: Accuracy = 0.90272\n",
      "Trial 8: Accuracy = 0.87897\n",
      "Trial 9: Accuracy = 0.83229\n",
      "Trial 10: Accuracy = 0.90517\n",
      "Trial 11: Accuracy = 0.90678\n",
      "Trial 12: Accuracy = 0.90562\n",
      "Trial 13: Accuracy = 0.89435\n",
      "Trial 14: Accuracy = 0.89056\n",
      "Trial 15: Accuracy = 0.86435\n",
      "Trial 16: Accuracy = 0.86345\n",
      "Trial 17: Accuracy = 0.90575\n",
      "Trial 18: Accuracy = 0.90684\n",
      "Trial 19: Accuracy = 0.90098\n",
      "Trial 20: Accuracy = 0.89996\n",
      "Trial 21: Accuracy = 0.90588\n",
      "Trial 22: Accuracy = 0.90549\n",
      "Trial 23: Accuracy = 0.89500\n",
      "Trial 24: Accuracy = 0.89410\n",
      "Trial 25: Accuracy = 0.89249\n",
      "Trial 26: Accuracy = 0.86480\n",
      "Trial 27: Accuracy = 0.90684\n",
      "Trial 28: Accuracy = 0.86841\n",
      "Trial 29: Accuracy = 0.66883\n",
      "\n",
      "Best CV Accuracy: 0.9068437367297448\n",
      "Best Hyperparameters:\n",
      "max_depth: 14\n",
      "min_child_weight: 9\n",
      "learning_rate: 0.062837454333107\n",
      "subsample: 0.9305075040142586\n",
      "colsample_bytree: 0.49499678480459114\n",
      "reg_alpha: 0.6946283469953012\n",
      "reg_lambda: 8.78860952747795\n",
      "gamma: 0.36495530512573554\n",
      "\n",
      "Saved predictions to submission_boxcox_std_target.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "\n",
    "# ---------------------\n",
    "# Settings\n",
    "# ---------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "TARGET = \"WeightCategory\"\n",
    "targetMap = {\n",
    "    'Insufficient_Weight':0,'Normal_Weight':1,\n",
    "    'Overweight_Level_I':2,'Overweight_Level_II':3, \n",
    "    'Obesity_Type_I':4,'Obesity_Type_II':5 ,'Obesity_Type_III':6\n",
    "}\n",
    "targetMap_reversed = {v:k for k,v in targetMap.items()}\n",
    "\n",
    "# ---------------------\n",
    "# Cross-validation function\n",
    "# ---------------------\n",
    "def cross_val_score_pipeline(X_tr, y_tr, pipeline, skf, verbose=False):\n",
    "    X = X_tr.copy()\n",
    "    y = y_tr.copy()\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        model = clone(pipeline)\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"FOLD {fold}: Accuracy = {acc:.5f}\")\n",
    "\n",
    "    mean_acc = np.mean(val_scores)\n",
    "    if verbose:\n",
    "        print(f\"Mean CV Accuracy: {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Pipeline preparation\n",
    "# ---------------------\n",
    "def xgb_pipeline(df_train, df_test, xgb_model):\n",
    "    X_train = df_train.copy()\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    # Drop ID if exists\n",
    "    if 'id' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['id'])\n",
    "    if 'id' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['id'])\n",
    "    \n",
    "    y_train = X_train.pop(TARGET).map(targetMap)\n",
    "\n",
    "    # numeric and categorical columns\n",
    "    numeric_cols = list(X_train.select_dtypes(exclude='object').columns)\n",
    "    categorical_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "    numeric_cols_without_age = [c for c in numeric_cols if c != 'Age']\n",
    "\n",
    "    # Numeric transformer (same as before)\n",
    "    num_transformer = ColumnTransformer([\n",
    "        ('boxcox', PowerTransformer(method='box-cox'), ['Age']),\n",
    "        ('scale', StandardScaler(), numeric_cols_without_age)\n",
    "    ])\n",
    "\n",
    "    # ðŸ”¹ Replace OrdinalEncoder with TargetEncoder\n",
    "    cat_transformer = TargetEncoder()\n",
    "\n",
    "    # Full preprocessor\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_transformer, numeric_cols),\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, xgb_model)\n",
    "    return X_train, y_train, X_test, pipeline\n",
    "\n",
    "# ---------------------\n",
    "# Optuna objective\n",
    "# ---------------------\n",
    "def objective(trial, pipeline, X_train, y_train, skf):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "    pipeline.named_steps['xgbclassifier'].set_params(**params)\n",
    "\n",
    "    mean_acc = cross_val_score_pipeline(X_train, y_train, pipeline, skf)\n",
    "    print(f\"Trial {trial.number}: Accuracy = {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Load data\n",
    "# ---------------------\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = df_test['id'].copy() if 'id' in df_test.columns else pd.Series(range(len(df_test)))\n",
    "\n",
    "# ---------------------\n",
    "# Prepare pipeline & model\n",
    "# ---------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, pipeline = xgb_pipeline(df_train, df_test, xgb_model)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Optuna hyperparameter tuning\n",
    "# ---------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    partial(objective, pipeline=pipeline, X_train=X_train, y_train=y_train, skf=skf),\n",
    "    n_trials=30\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Best trial results\n",
    "# ---------------------\n",
    "trial = study.best_trial\n",
    "print(\"\\nBest CV Accuracy:\", trial.value)\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------------\n",
    "# Train final model with best hyperparameters\n",
    "# ---------------------\n",
    "best_params = trial.params\n",
    "xgb_model_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, final_pipeline = xgb_pipeline(df_train, df_test, xgb_model_final)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------\n",
    "# Predict on test set\n",
    "# ---------------------\n",
    "test_preds_numeric = final_pipeline.predict(X_test)\n",
    "test_preds_labels = [targetMap_reversed[i] for i in test_preds_numeric]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'WeightCategory': test_preds_labels\n",
    "})\n",
    "submission.to_csv(\"submission_boxcox_std_target.csv\", index=False)\n",
    "print(\"\\nSaved predictions to submission_boxcox_std_target.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe563c",
   "metadata": {},
   "source": [
    "**The above gave 91.1% accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab972174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0: Accuracy = 0.82624\n",
      "Trial 1: Accuracy = 0.87910\n",
      "Trial 2: Accuracy = 0.86358\n",
      "Trial 3: Accuracy = 0.75137\n",
      "Trial 4: Accuracy = 0.88109\n",
      "Trial 5: Accuracy = 0.85109\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from xgboost import XGBClassifier\n",
    "import optuna\n",
    "from functools import partial\n",
    "import warnings\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "\n",
    "# ---------------------\n",
    "# Settings\n",
    "# ---------------------\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "TARGET = \"WeightCategory\"\n",
    "targetMap = {\n",
    "    'Insufficient_Weight':0,'Normal_Weight':1,\n",
    "    'Overweight_Level_I':2,'Overweight_Level_II':3, \n",
    "    'Obesity_Type_I':4,'Obesity_Type_II':5 ,'Obesity_Type_III':6\n",
    "}\n",
    "targetMap_reversed = {v:k for k,v in targetMap.items()}\n",
    "\n",
    "# ---------------------\n",
    "# Cross-validation function\n",
    "# ---------------------\n",
    "def cross_val_score_pipeline(X_tr, y_tr, pipeline, skf, verbose=False):\n",
    "    X = X_tr.copy()\n",
    "    y = y_tr.copy()\n",
    "    val_scores = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        model = clone(pipeline)\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        acc = accuracy_score(y_val, y_pred)\n",
    "        val_scores.append(acc)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"FOLD {fold}: Accuracy = {acc:.5f}\")\n",
    "\n",
    "    mean_acc = np.mean(val_scores)\n",
    "    if verbose:\n",
    "        print(f\"Mean CV Accuracy: {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Pipeline preparation\n",
    "# ---------------------\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, PowerTransformer, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "def xgb_pipeline(df_train, df_test, xgb_model):\n",
    "    X_train = df_train.copy()\n",
    "    X_test = df_test.copy()\n",
    "\n",
    "    # Drop ID if exists\n",
    "    if 'id' in X_train.columns:\n",
    "        X_train = X_train.drop(columns=['id'])\n",
    "    if 'id' in X_test.columns:\n",
    "        X_test = X_test.drop(columns=['id'])\n",
    "    \n",
    "    y_train = X_train.pop(TARGET).map(targetMap)\n",
    "\n",
    "    numeric_cols = list(X_train.select_dtypes(exclude='object').columns)\n",
    "    categorical_cols = list(X_train.select_dtypes(include='object').columns)\n",
    "\n",
    "    numeric_cols_without_age = [c for c in numeric_cols if c != 'Age']\n",
    "\n",
    "    # Numeric transformer with interaction terms\n",
    "    num_transformer = ColumnTransformer([\n",
    "        ('boxcox', PowerTransformer(method='box-cox'), ['Age']),\n",
    "        ('poly', make_pipeline(StandardScaler(), PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)), numeric_cols_without_age)\n",
    "    ])\n",
    "\n",
    "    # Use OrdinalEncoder since TargetEncoder didnâ€™t help\n",
    "    cat_transformer = OrdinalEncoder()\n",
    "\n",
    "    # Full preprocessor\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', num_transformer, numeric_cols),\n",
    "        ('cat', cat_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    pipeline = make_pipeline(preprocessor, xgb_model)\n",
    "    return X_train, y_train, X_test, pipeline\n",
    "\n",
    "\n",
    "# ---------------------\n",
    "# Optuna objective\n",
    "# ---------------------\n",
    "def objective(trial, pipeline, X_train, y_train, skf):\n",
    "    params = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 20),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-4, 0.1, log=True),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.1, 1.0),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-2, 10.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 10.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 5.0)\n",
    "    }\n",
    "    pipeline.named_steps['xgbclassifier'].set_params(**params)\n",
    "\n",
    "    mean_acc = cross_val_score_pipeline(X_train, y_train, pipeline, skf)\n",
    "    print(f\"Trial {trial.number}: Accuracy = {mean_acc:.5f}\")\n",
    "    return mean_acc\n",
    "\n",
    "# ---------------------\n",
    "# Load data\n",
    "# ---------------------\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Save test IDs for submission\n",
    "test_ids = df_test['id'].copy() if 'id' in df_test.columns else pd.Series(range(len(df_test)))\n",
    "\n",
    "# ---------------------\n",
    "# Prepare pipeline & model\n",
    "# ---------------------\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    eval_metric=\"mlogloss\"\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, pipeline = xgb_pipeline(df_train, df_test, xgb_model)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# ---------------------\n",
    "# Optuna hyperparameter tuning\n",
    "# ---------------------\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(\n",
    "    partial(objective, pipeline=pipeline, X_train=X_train, y_train=y_train, skf=skf),\n",
    "    n_trials=30\n",
    ")\n",
    "\n",
    "# ---------------------\n",
    "# Best trial results\n",
    "# ---------------------\n",
    "trial = study.best_trial\n",
    "print(\"\\nBest CV Accuracy:\", trial.value)\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in trial.params.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# ---------------------\n",
    "# Train final model with best hyperparameters\n",
    "# ---------------------\n",
    "best_params = trial.params\n",
    "xgb_model_final = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    n_jobs=-1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "X_train, y_train, X_test, final_pipeline = xgb_pipeline(df_train, df_test, xgb_model_final)\n",
    "final_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ---------------------\n",
    "# Predict on test set\n",
    "# ---------------------\n",
    "test_preds_numeric = final_pipeline.predict(X_test)\n",
    "test_preds_labels = [targetMap_reversed[i] for i in test_preds_numeric]\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'WeightCategory': test_preds_labels\n",
    "})\n",
    "submission.to_csv(\"submission_boxcox_std_label_poly.csv\", index=False)\n",
    "print(\"\\nSaved predictions to submission_boxcox_std_label_poly.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0dd78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
